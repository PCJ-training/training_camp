{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequencing data analysis\n",
    "\n",
    "### IMPORTANT: Please make sure that your are using the bash kernel to run this notebook.\n",
    "\n",
    "### This notebook covers analysis of DNA sequencing data from raw files to processed signals.\n",
    "\n",
    "Although this analysis is for ATAC-seq data, many of the steps (especially the first section) are the same for other types of DNA sequencing experiments.\n",
    "\n",
    "We'll be doing the analysis in Bash, which is the standard language for UNIX command-line scripting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setting up the data\n",
    "\n",
    "We start with raw `.fastq.gz` files, which are provided by the sequencing instrument. For each DNA molecule (read) that was sequenced, they provide the nucleotide sequence, and information about the quality of the signal of that nucleotide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "### Set up variables storing the location of our data\n",
    "### The proper way to load your variables is with the ~/.bashrc command, but this is very slow in iPython \n",
    "export SUNETID=\"$(whoami)\"\n",
    "export WORK_DIR=\"/srv/scratch/training_camp/tc2016/${SUNETID}\"\n",
    "export DATA_DIR=\"${WORK_DIR}/data\"\n",
    "export FASTQ_DIR=\"${DATA_DIR}/fastq/\"\n",
    "export SRC_DIR=\"${WORK_DIR}/src/training_camp/src/\"\n",
    "export ANALYSIS_DIR=\"${WORK_DIR}/analysis/\"\n",
    "export YEAST_DIR=\"/srv/scratch/training_camp/saccer3/seq\"\n",
    "export YEAST_INDEX=\"/srv/scratch/training_camp/saccer3/bowtie2_index/saccer3\"\n",
    "export YEAST_CHR=\"/srv/scratch/training_camp/saccer3/sacCer3.chrom.sizes\"\n",
    "export TMP=\"${WORK_DIR}/tmp\"\n",
    "export TEMP=$TMP \n",
    "export TMPDIR=$TMP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check exactly which fastqs we have:\n",
    "\n",
    "(recall that the `ls` command lists the contents of a directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls $FASTQ_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As a sanity check, we can also look at the size and last edited time of some of the fastqs by addind `-lrth` to the `ls` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls -lrth $FASTQ_DIR | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also inspect the format of one of the fastqs. Notice that each read takes up 4 lines:\n",
    "1. the read name\n",
    "2. the read's nucleotide sequence\n",
    "3. a '+' to indicate the record contains another line\n",
    "4. a quality score for each base (a number encoded as a letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zcat $(ls $FASTQ_DIR* | head -n 1) | head -n 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Adapter trimming\n",
    "\n",
    "- In many kinds of DNA and RNA sequencing experiments, sometimes the sequences will read through the targeted sequence insert and into sequencing adapter or PCR primer sequences on the end of the fragment. When the insert size is shorter than the read length (like in some of our ATAC-seq reads), the adapter sequence is read by the sequencer.\n",
    "\n",
    "- We need to remove such adapter sequences because they won't align to the genome.\n",
    "\n",
    "- In ATAC-seq (the data we're analyzing), the fragment length follows a periodic distribution. Some reads have very short inserts (only a few basepairs), while other reads have inserts that are much longer (100's of basepairs — much longer than the 77bp reads we're using to read them.\n",
    "\n",
    "- We know ahead of time that the first part of the adapter sequence is `CTGTCTCTTATA`, since our reads are sequenced using a Nextera sample prep kit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's sanity check our adapter sequence by seeing\n",
    "# how many times it occurs in the first 100000 reads.\n",
    "\n",
    "ADAPTER=\"CTGTCTCTTATA\"\n",
    "\n",
    "NUM_LINES=400000  # 4 * num_reads, since each fastq entry is 4 lines\n",
    "\n",
    "zcat $(ls $FASTQ_DIR*R1* | head -n 1) | head -n $NUM_LINES | grep $ADAPTER | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's also check how often a permutation (rearrangement)\n",
    "# of the adapter sequence occurs:\n",
    "\n",
    "NOT_ADAPTER=\"CGTTCTTCTATA\"  # A permutation of the adapter sequence\n",
    "\n",
    "zcat $(ls $FASTQ_DIR*R1* | head -n 1) | head -n $NUM_LINES | grep $NOT_ADAPTER | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the correct adapter sequence occurs *many* times more in the reads than a permutation of the adapter sequene — this is an important validation that we have the right sequence.\n",
    "\n",
    "Now, we'll trim the paired-end reads using a tool called `cutadapt`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a directory to store the trimmed data \n",
    "export TRIMMED_DIR=\"$ANALYSIS_DIR/trimmed/\"\n",
    "[[ ! -d $TRIMMED_DIR ]] && mkdir -p \"$TRIMMED_DIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for R1_fastq in ${FASTQ_DIR}*_R1*fastq.gz; do\n",
    "    \n",
    "    # Get the read 2 fastq file from the filename of read 1\n",
    "    R2_fastq=$(echo $R1_fastq | sed -e 's/R1/R2/')\n",
    "    \n",
    "    # Generate names for the trimmed fastq files\n",
    "\n",
    "    trimmed_R1_fastq=$TRIMMED_DIR$(echo $(basename $R1_fastq)| sed -e 's/.fastq.gz/.trimmed.fastq.gz/')\n",
    "    trimmed_R2_fastq=$TRIMMED_DIR$(echo $(basename $R2_fastq)| sed -e 's/.fastq.gz/.trimmed.fastq.gz/')   \n",
    "    echo cutadapt -m 5 -e 0.20 -a CTGTCTCTTATA -A CTGTCTCTTATA \\\n",
    "        -o ${trimmed_R1_fastq} \\\n",
    "        -p ${trimmed_R2_fastq} \\\n",
    "        $R1_fastq \\\n",
    "        $R2_fastq\n",
    "    cutadapt -m 5 -e 0.20 -a CTGTCTCTTATA -A CTGTCTCTTATA \\\n",
    "        -o ${trimmed_R1_fastq} \\\n",
    "        -p ${trimmed_R2_fastq} \\\n",
    "        $R1_fastq \\\n",
    "        $R2_fastq\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Part 3: Alignment\n",
    "\n",
    "Now, we're ready to align our trimmed reads to the Yeast SacCer3 reference genome.\n",
    "\n",
    "We'll use [Bowtie2](http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml), which is a [Burrows-Wheeler](https://en.wikipedia.org/wiki/Burrows%E2%80%93Wheeler_transform) based spliced aligner.\n",
    "\n",
    "Bowtie2 outputs a SAM (Sequence Alignment Map) file, which is a standard text encoding. To save space, we'll use `samtools view -b` to encode the output as a binarized SAM file — a BAM file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#set the bowtie index\n",
    "export bowtie_index=$YEAST_INDEX\n",
    "echo $bowtie_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#create a directory to store the aligned data \n",
    "export ALIGNMENT_DIR=\"$ANALYSIS_DIR/aligned/\"\n",
    "[[ ! -d $ALIGNMENT_DIR ]] && mkdir -p \"$ALIGNMENT_DIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for trimmed_fq1 in ${TRIMMED_DIR}*_R1*fastq.gz; do\n",
    "\n",
    "    trimmed_fq2=$(echo $trimmed_fq1 | sed -e 's/_R1/_R2/')\n",
    "    \n",
    "    bam=$(echo \"${ALIGNMENT_DIR}${trimmed_fq1##*/}\" | sed -e 's/.fastq.gz/.bam/')\n",
    "    bowtie2 -X2000 --mm --threads 5 -x $bowtie_index -1 $trimmed_fq1 -2 $trimmed_fq2 | samtools view -bS - > $bam        \n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Finding duplicate reads and alignment filtering\n",
    "\n",
    "During sequencing, we perform PCR, which can lead to duplicate reads. In many kinds of DNA sequencing, we want to remove duplicates so that we don't double-count signal originating from the same molecule.\n",
    "\n",
    "To do so, we use an algorithm called `sambamba` that looks for reads that mapped to exactly the same places in the genome. We also need to sort the aligned files before we can mark duplicates, since we need reads aligned to the same position to be next to each other in the file.\n",
    "\n",
    "Bowtie2 also sets certian labels (or \"flags\") in the resulting alignment file to indicate information like the score of the alignment, the orientation of both mates of the fragment, and other details.\n",
    "\n",
    "We can use these flags as a way to discard low-quality reads. [This website](https://broadinstitute.github.io/picard/explain-flags.html) provides a convenient way to interpret the meaning of these bitwise flags; for conveninece they can be encoded as numbers.\n",
    "\n",
    "Here, we want to filter reads that fall into any of the following categories:\n",
    "- the read wasn't mapped to the genome\n",
    "- the read's mate wasn't mapped to the genome\n",
    "- the alignment reported is not the primary alignment (it is a \"runner-up\" alignment)\n",
    "- the read was marked as \"low-quality\" by the sequencer software\n",
    "- the read has a mapping quality less than 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for bam_file in ${ALIGNMENT_DIR}*.trimmed.bam; do\n",
    "\n",
    "    bam_file_sorted=$(echo $bam_file | sed -e 's/.bam/.sorted.bam/')\n",
    "    bam_file_dup=$(echo $bam_file | sed -e 's/.bam/.sorted.dup.bam/')\n",
    "    nodup_bam_file=$(echo $bam_file | sed -e 's/.bam/.nodup.bam/')\n",
    "    \n",
    "    # Sort and remove duplicates\n",
    "    sambamba sort -m 4G -t 2 -u $bam_file \n",
    "    sambamba markdup -l 0 -t 2 $bam_file_sorted $bam_file_dup\n",
    "    samtools view -F 1804 -f 2 -q 30 -b $bam_file_dup  > $nodup_bam_file\n",
    "    \n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Peak calling\n",
    "\n",
    "Now that we've aligned our reads to the genome and filtered the alignments, we want to identify areas of locally enriched signals, or \"peaks\".\n",
    "\n",
    "For ATAC-seq, peaks correspond to accessible regions. They can include promoters, enhancers, and other regulatory regions.\n",
    "\n",
    "We'll call peaks using [MACS2](http://liulab.dfci.harvard.edu/MACS/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#create a directory to store the tagAlign data \n",
    "TAGALIGN_DIR=\"${ANALYSIS_DIR}tagAlign/\"\n",
    "[[ ! -d $TAGALIGN_DIR ]] && mkdir -p \"$TAGALIGN_DIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#create a directory to store the MACS peaks \n",
    "PEAKS_DIR=\"${ANALYSIS_DIR}peaks/\"\n",
    "[[ ! -d $PEAKS_DIR ]] && mkdir -p \"$PEAKS_DIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SacCer3GenSz=12157105  # The sum of the sizes of the chromosomes in the SacCer3 genome\n",
    "\n",
    "Macs2PvalThresh=\"0.05\"  # The p-value threshold for calling peaks \n",
    "\n",
    "Macs2SmoothWindow=150  # The window size to smooth alignment signal over\n",
    "Macs2ShiftSize=$(python -c \"print(int(${Macs2SmoothWindow}/2))\")\n",
    "\n",
    "for nodup_bam_file in ${ALIGNMENT_DIR}*.nodup.bam; do\n",
    "    \n",
    "    # First, we need to convert each bam to a .tagAlign,\n",
    "    # which just contains the start/end positions of each read:\n",
    "    \n",
    "    tagalign_file=$TAGALIGN_DIR$(echo $(basename $nodup_bam_file) | sed -e 's/.bam/.tagAlign.gz/')\n",
    "    bedtools bamtobed -i $nodup_bam_file | awk 'BEGIN{OFS=\"\\t\"}{$4=\"N\";$5=\"1000\";print $0}' | gzip -c > $tagalign_file\n",
    "    \n",
    "    # Now, we can run MACS:\n",
    "    output_prefix=$PEAKS_DIR$(echo $(basename $tagalign_file)| sed -e 's/.tagAlign.gz//')\n",
    "     macs2 callpeak \\\n",
    "        -t $tagalign_file -f BED -n $output_prefix -g \"$SacCer3GenSz\" -p $Macs2PvalThresh \\\n",
    "        --nomodel --shift -$Macs2ShiftSize --extsize $Macs2SmoothWindow -B --SPMR --keep-dup all --call-summits\n",
    "\n",
    "    #We also generate a fold change file comparing the sample to the control(DMSO)\n",
    "    macs2 bdgcmp -t $output_prefix\\_treat_pileup.bdg -c $output_prefix\\_control_lambda.bdg -o $output_prefix\\_FE.bdg -m FE\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we merge the peaks across all conditions to create a master list of peaks for analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "cd $PEAKS_DIR\n",
    "#concatenate all .narrowPeak files together \n",
    "cat *narrowPeak > all.peaks.bed \n",
    "\n",
    "#sort the concatenated file \n",
    "bedtools sort -i all.peaks.bed > all.peaks.sorted.bed \n",
    "\n",
    "#merge the sorted, concatenated fileto join overlapping peaks \n",
    "bedtools merge -i all.peaks.sorted.bed > all_merged.peaks.bed\n",
    "gzip -f all_merged.peaks.bed \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
